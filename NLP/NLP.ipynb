{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "m1HPcvwWzn8F"
      },
      "outputs": [],
      "source": [
        "example = \"\"\"Natural language processing (NLP) is a subfield of computer science and liguistics.\n",
        "It's concerned with giving computers the ability to support and manipulate human language.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download('punkt_tab')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu38Ks4L2GMW",
        "outputId": "358b2dac-78b0-4667-d667-e78b93e75d62"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(example)"
      ],
      "metadata": {
        "id": "KTa94KKt2neD"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_I0ocbN2y8T",
        "outputId": "2889f89d-f83e-40b8-9a29-10b8af4a1fce"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural language processing (NLP) is a subfield of computer science and liguistics.',\n",
              " \"It's concerned with giving computers the ability to support and manipulate human language.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDbmZ_I_21Gz",
        "outputId": "4010a571-110c-4822-c013-18b813a1078e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words=word_tokenize(example)"
      ],
      "metadata": {
        "id": "MAkQp5ZB3CkS"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcqLujM93GdS",
        "outputId": "dab12416-00fd-472f-85ae-981e4ce9cc7a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " '(',\n",
              " 'NLP',\n",
              " ')',\n",
              " 'is',\n",
              " 'a',\n",
              " 'subfield',\n",
              " 'of',\n",
              " 'computer',\n",
              " 'science',\n",
              " 'and',\n",
              " 'liguistics',\n",
              " '.',\n",
              " 'It',\n",
              " \"'s\",\n",
              " 'concerned',\n",
              " 'with',\n",
              " 'giving',\n",
              " 'computers',\n",
              " 'the',\n",
              " 'ability',\n",
              " 'to',\n",
              " 'support',\n",
              " 'and',\n",
              " 'manipulate',\n",
              " 'human',\n",
              " 'language',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ywt_R2hz3HyS",
        "outputId": "8031101d-4654-4437-eea2-5b3ffb4b0bb2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "k_fPZJci3XDS"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWEl5Hc-3o7-",
        "outputId": "be3a6d14-5b0e-41dd-d379-efdc53d29b0c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "zu0ENgAu3vn0"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JDSJ5tmX4AhJ",
        "outputId": "3e421ebb-9f4d-4a25-926f-f662314c1d61"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he'd\",\n",
              " \"he'll\",\n",
              " \"he's\",\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " \"i've\",\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she'd\",\n",
              " \"she'll\",\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " \"we've\",\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_list = [word for word in words if word.casefold() not in stop_words]"
      ],
      "metadata": {
        "id": "40159PSn4B7Y"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkjkJ_1k4eTC",
        "outputId": "26ef84ac-8b64-43de-e23d-5cb6399ccbbc"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " '(',\n",
              " 'NLP',\n",
              " ')',\n",
              " 'subfield',\n",
              " 'computer',\n",
              " 'science',\n",
              " 'liguistics',\n",
              " '.',\n",
              " \"'s\",\n",
              " 'concerned',\n",
              " 'giving',\n",
              " 'computers',\n",
              " 'ability',\n",
              " 'support',\n",
              " 'manipulate',\n",
              " 'human',\n",
              " 'language',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer=PorterStemmer()"
      ],
      "metadata": {
        "id": "adVus9cA4fdi"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_words=[stemmer.stem(word) for word in words]"
      ],
      "metadata": {
        "id": "rOcxvP3F45na"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Hb8fJy_5FQ6",
        "outputId": "82483c5f-709d-4818-a93b-3f58c41ef44b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['natur',\n",
              " 'languag',\n",
              " 'process',\n",
              " '(',\n",
              " 'nlp',\n",
              " ')',\n",
              " 'is',\n",
              " 'a',\n",
              " 'subfield',\n",
              " 'of',\n",
              " 'comput',\n",
              " 'scienc',\n",
              " 'and',\n",
              " 'liguist',\n",
              " '.',\n",
              " 'it',\n",
              " \"'s\",\n",
              " 'concern',\n",
              " 'with',\n",
              " 'give',\n",
              " 'comput',\n",
              " 'the',\n",
              " 'abil',\n",
              " 'to',\n",
              " 'support',\n",
              " 'and',\n",
              " 'manipul',\n",
              " 'human',\n",
              " 'languag',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "stemmer=SnowballStemmer('english')"
      ],
      "metadata": {
        "id": "nkPGl8IX5HBK"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_words2 = [stemmer.stem(word) for word in words]"
      ],
      "metadata": {
        "id": "UgudQtq85hK5"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_words2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sS6-i-g5qB4",
        "outputId": "5b511cf7-864d-4bd1-fc2b-8d7593d10c2a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['natur',\n",
              " 'languag',\n",
              " 'process',\n",
              " '(',\n",
              " 'nlp',\n",
              " ')',\n",
              " 'is',\n",
              " 'a',\n",
              " 'subfield',\n",
              " 'of',\n",
              " 'comput',\n",
              " 'scienc',\n",
              " 'and',\n",
              " 'liguist',\n",
              " '.',\n",
              " 'it',\n",
              " \"'s\",\n",
              " 'concern',\n",
              " 'with',\n",
              " 'give',\n",
              " 'comput',\n",
              " 'the',\n",
              " 'abil',\n",
              " 'to',\n",
              " 'support',\n",
              " 'and',\n",
              " 'manipul',\n",
              " 'human',\n",
              " 'languag',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "RXpt5hP15uJo"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lematizer=WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "DbzpOxBr6BnH"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH37832k6JZn",
        "outputId": "88b1f939-c537-4f56-e97e-e101067b21c6"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lematizer.lemmatize('thieves')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jy7w-bdC6MK2",
        "outputId": "7859325f-17e7-4823-9f2d-693b0654f55c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thief'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lematizer.lemmatize('worst')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cPzZmB3T6bYW",
        "outputId": "de5e162c-f15a-4c7f-fbda-abf911311a58"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'worst'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lematizer.lemmatize('worst', pos='a')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K1kFQE1j6jj1",
        "outputId": "d594b065-13c4-47ee-d8b1-88e7d047613e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuijAHqT61b0",
        "outputId": "136afef8-7de1-407c-ecf2-114ff2bb3c35"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.pos_tag(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so0KM_om7NFT",
        "outputId": "5a7aa4b7-05fb-45aa-ecd0-b759dcb9ec83"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Natural', 'JJ'),\n",
              " ('language', 'NN'),\n",
              " ('processing', 'NN'),\n",
              " ('(', '('),\n",
              " ('NLP', 'NNP'),\n",
              " (')', ')'),\n",
              " ('is', 'VBZ'),\n",
              " ('a', 'DT'),\n",
              " ('subfield', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('computer', 'NN'),\n",
              " ('science', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('liguistics', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('It', 'PRP'),\n",
              " (\"'s\", 'VBZ'),\n",
              " ('concerned', 'VBN'),\n",
              " ('with', 'IN'),\n",
              " ('giving', 'VBG'),\n",
              " ('computers', 'NNS'),\n",
              " ('the', 'DT'),\n",
              " ('ability', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('support', 'VB'),\n",
              " ('and', 'CC'),\n",
              " ('manipulate', 'VB'),\n",
              " ('human', 'JJ'),\n",
              " ('language', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hmv5jBkf7kdX",
        "outputId": "00e6cc72-ae9b-47d6-f9b5-3092cc334f11"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.55.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "k9sl5ORk8Qpo"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "6QRsT1IZ8zPu"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = model.encode(example)"
      ],
      "metadata": {
        "id": "CNGTJ8aM9EU9"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CMD_2kZx9POd",
        "outputId": "99336495-1007-4f32-baf7-62e1bf8c9636"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 7.63483951e-03 -2.36063749e-02  5.47219552e-02 -1.71165857e-02\n",
            "  3.10756341e-02 -1.75687801e-02  3.06161549e-02  2.50275619e-02\n",
            " -1.83027908e-02  3.55548449e-02 -1.18125752e-02 -2.19016522e-03\n",
            " -8.74949328e-05  1.07853748e-02  6.95303902e-02  8.55788067e-02\n",
            " -9.09885019e-03 -3.43363211e-02 -6.09980784e-02 -4.36937399e-02\n",
            "  2.71246191e-02  8.74860138e-02 -8.61152932e-02 -4.70523126e-02\n",
            "  4.03631441e-02  8.86770263e-02 -3.70660760e-02 -5.63942641e-02\n",
            "  4.81498092e-02  2.91466359e-02  5.00762078e-04  1.36128636e-02\n",
            "  3.46877314e-02  1.01392016e-01 -3.01228836e-02  6.57725781e-02\n",
            "  4.27579827e-04  1.64930604e-03 -2.77404878e-02 -2.12131217e-02\n",
            " -8.86597559e-02 -2.40936112e-02 -5.53331226e-02  3.82887735e-03\n",
            "  1.16902128e-01  7.38398451e-03 -1.21722750e-01  2.84699760e-02\n",
            " -9.28271264e-02 -1.24198589e-02 -1.14037119e-01  3.08112055e-02\n",
            "  5.90500608e-02  8.94933641e-02 -6.63039833e-02  2.94000506e-02\n",
            "  1.28335701e-02 -2.28534155e-02 -2.03745961e-02 -1.02535233e-01\n",
            " -3.49764414e-02 -4.64759618e-02 -1.79118034e-03  5.98670803e-02\n",
            "  5.04873879e-02  4.19262657e-03 -3.22767124e-02 -1.39623256e-02\n",
            "  5.43872863e-02 -4.36683968e-02 -2.12837104e-02  4.44000028e-02\n",
            "  2.82104630e-02  1.03566356e-01 -1.30530968e-02 -1.14124054e-02\n",
            " -3.16062476e-03 -5.42043038e-02  8.72479305e-02 -4.36852984e-02\n",
            "  3.12879831e-02  6.57307506e-02  4.23377343e-02  7.90203437e-02\n",
            "  4.45891358e-02 -4.12548482e-02 -2.41924240e-03  2.43104231e-02\n",
            " -6.81006461e-02  1.32270670e-03 -5.00251576e-02 -1.05791278e-01\n",
            "  6.89375028e-02 -1.26178041e-02 -6.20223358e-02  5.69353178e-02\n",
            " -5.37712015e-02 -1.09163947e-01  2.41513979e-02 -8.30199663e-03\n",
            "  1.98974628e-02  4.76423055e-02 -6.04120176e-03 -7.81731233e-02\n",
            " -7.08513930e-02 -2.12888904e-02 -2.75190342e-02 -2.52413005e-02\n",
            "  3.07413898e-02 -1.01908199e-01 -2.18653753e-02  1.41876182e-02\n",
            " -3.29979025e-02 -1.13938460e-02  6.44758269e-02 -3.35277729e-02\n",
            "  7.54722580e-03  2.29111733e-03  7.44314417e-02  5.06270155e-02\n",
            " -1.04573511e-01  3.26762423e-02 -4.36166897e-02  3.82258929e-02\n",
            "  3.70802321e-02 -4.68040518e-02  5.33184633e-02 -1.21239349e-33\n",
            "  1.10949008e-02 -2.10317411e-02 -5.46600074e-02 -3.57718393e-02\n",
            "  7.54274949e-02 -2.99762618e-02 -2.82695573e-02 -1.49166808e-02\n",
            " -7.83455819e-02 -1.05437450e-02  5.77438660e-02 -2.37494204e-02\n",
            "  1.76551379e-03  1.76909342e-02  7.03183860e-02  2.02153660e-02\n",
            " -4.39116731e-02  6.46944419e-02  4.21070643e-02 -1.19130636e-04\n",
            " -3.75547037e-02  8.17240104e-02  2.99701318e-02  9.33803804e-03\n",
            " -3.67203914e-02  4.80665937e-02 -5.64088449e-02 -4.02751304e-02\n",
            "  3.55903730e-02 -7.80224102e-04  1.92847215e-02  8.00417289e-02\n",
            " -8.12991485e-02  2.10695397e-02  9.40735545e-03 -6.03830107e-02\n",
            "  3.88636068e-02 -4.63150851e-02  2.07882635e-02 -4.08221222e-02\n",
            " -5.24430983e-02  4.44609486e-02  2.74156593e-03  4.04705293e-02\n",
            "  2.58764811e-02  3.72916125e-02 -6.44082204e-02 -4.16431352e-02\n",
            "  1.64861344e-02 -2.28625163e-02  7.52881020e-02 -4.21454199e-03\n",
            "  4.59685251e-02  7.19804922e-03  1.18665315e-01  3.42290699e-02\n",
            " -1.11579793e-02 -2.93560904e-02  1.74144953e-02  4.12459895e-02\n",
            "  6.58293441e-02  1.54553475e-02  4.37377170e-02 -2.77082473e-02\n",
            "  3.56236473e-02 -1.46036483e-02  4.60917912e-02 -2.28341352e-02\n",
            "  5.88709936e-02 -1.10322321e-02 -2.48600133e-02  2.43727602e-02\n",
            "  2.09203130e-03  6.09264821e-02  2.75661405e-02 -1.46023836e-02\n",
            "  4.60592359e-02 -3.23434100e-02 -1.27459196e-02  1.30653754e-01\n",
            " -8.68190527e-02 -1.28477752e-01  3.62020768e-02 -6.05437085e-02\n",
            "  2.61853579e-02 -4.51698005e-02 -4.10677530e-02  4.87236306e-02\n",
            "  6.53008670e-02 -1.67839602e-02  6.44046580e-03  4.94443588e-02\n",
            " -5.26335090e-02  5.99343143e-02 -2.72746794e-02 -6.98908717e-34\n",
            " -8.23567957e-02 -2.34816391e-02 -1.33808494e-01  7.39321932e-02\n",
            " -3.42895165e-02 -7.67973885e-02 -2.49320175e-02 -4.50528003e-02\n",
            "  4.92702983e-02 -1.22026587e-02  9.89170652e-03 -5.92075139e-02\n",
            "  8.93045664e-02  2.47588512e-02  5.80423176e-02 -1.54084340e-02\n",
            " -4.22185473e-02  5.82079366e-02 -2.07390357e-02  8.76870006e-02\n",
            "  2.00743284e-02  5.86212687e-02 -9.76995826e-02  1.39132971e-02\n",
            "  6.81168661e-02  1.17774019e-02 -7.43011981e-02 -3.53509374e-02\n",
            " -2.99160890e-02 -4.83321398e-03  9.29157156e-03  5.67570627e-02\n",
            " -5.09842858e-02 -1.56408362e-02  4.03444059e-02 -4.09500636e-02\n",
            " -9.62760672e-03 -1.17865577e-02 -7.00209104e-03 -2.64743511e-02\n",
            "  8.13612193e-02  1.10681772e-01 -6.30041063e-02 -2.74337642e-02\n",
            " -5.78773394e-02  1.93802342e-02 -8.84516314e-02 -1.06358780e-02\n",
            "  2.11351085e-02  1.53773837e-02 -3.24427895e-03 -2.40113456e-02\n",
            " -2.25681774e-02 -3.72367799e-02 -3.49993519e-02  6.75992901e-03\n",
            "  3.45947593e-02 -8.31706375e-02 -7.09385797e-02  1.80831440e-02\n",
            " -6.66686669e-02  3.40601169e-02  1.04732640e-01 -2.42142137e-02\n",
            "  3.45504135e-02 -1.50755560e-02 -6.41357675e-02  3.44319046e-02\n",
            " -6.80333748e-02 -6.95670322e-02  5.95973469e-02  5.74038066e-02\n",
            "  2.34619472e-02  7.67188221e-02 -2.77289413e-02 -1.53183164e-02\n",
            "  7.85482489e-03 -3.90337482e-02 -4.21357229e-02 -3.61361429e-02\n",
            "  1.20339878e-01  2.34553032e-02  3.69394571e-02  4.54098219e-03\n",
            " -4.29268256e-02  4.41966578e-02 -2.84417402e-02  3.67726125e-02\n",
            " -1.16168782e-02 -2.81658657e-02 -1.30102476e-02 -2.61203609e-02\n",
            " -5.63355759e-02  1.10235423e-01 -6.25846982e-02 -3.23823564e-08\n",
            " -6.97104037e-02 -1.80472042e-02 -1.24942539e-02 -6.80003641e-03\n",
            "  7.36881746e-03  1.25341117e-02 -2.77427528e-02  3.88386985e-03\n",
            " -3.21041271e-02 -7.96470419e-02  4.78096455e-02  7.21831024e-02\n",
            " -4.71155792e-02 -5.05671389e-02  3.45444232e-02 -1.46890548e-03\n",
            "  4.16649505e-02 -4.74200770e-02  2.55085658e-02 -4.73455749e-02\n",
            "  1.06136180e-01 -1.00574289e-02 -4.78321575e-02  1.06897041e-01\n",
            "  1.09600611e-02 -3.25032398e-02 -5.32910116e-02 -1.02842611e-03\n",
            "  1.33587550e-02 -9.04266909e-02  1.42730051e-03  6.10963255e-02\n",
            " -1.48228677e-02  6.27246648e-02  1.30293265e-01  5.18934578e-02\n",
            " -1.56308804e-03 -1.39955327e-01 -6.55404180e-02 -2.13579237e-02\n",
            "  9.38251149e-03  8.74195844e-02 -3.68509516e-02 -3.67780440e-02\n",
            "  4.60795313e-02  1.55390613e-02  1.08528240e-02 -1.18210621e-01\n",
            " -1.16914595e-02 -8.12863838e-03  1.13445765e-03 -3.16395201e-02\n",
            " -1.08949430e-02  4.29332145e-02  4.48734090e-02 -2.62013800e-03\n",
            " -6.35707285e-03  2.35316739e-03 -4.54705097e-02 -1.66733060e-02\n",
            " -6.74824640e-02  1.23208553e-01  1.06384031e-01 -2.84208311e-03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTtYg7Wz9SJd",
        "outputId": "334f765b-77c5-4c50-cb65-8b69cd29795e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "UwGeoDq99esM"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['computer', 'laptop', 'car', 'motorbike', 'flower']"
      ],
      "metadata": {
        "id": "Rx64FmnM9wur"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = model.encode(words)"
      ],
      "metadata": {
        "id": "NfVUTeXb-CTq"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46JRUpzc-JCa",
        "outputId": "685ab099-9ec5-4b18-ddac-219ae6325fc7"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "dPHUWSFw-Mzq"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools"
      ],
      "metadata": {
        "id": "ab4nAPGQ-1HI"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (i,word1), (j,word2) in itertools.combinations(enumerate(words), 2):\n",
        "    sim = cosine_similarity([embeddings[i]], [embeddings[j]])[0][0]\n",
        "    print(f\"{word1:10} {word2:10}, podobienstwo {sim: .4F}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KDNTDNR-_4o",
        "outputId": "8868bf9c-2a88-45dd-fd52-e214d3f049a3"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computer   laptop    , podobienstwo  0.7140\n",
            "computer   car       , podobienstwo  0.5321\n",
            "computer   motorbike , podobienstwo  0.3913\n",
            "computer   flower    , podobienstwo  0.3406\n",
            "laptop     car       , podobienstwo  0.4516\n",
            "laptop     motorbike , podobienstwo  0.4111\n",
            "laptop     flower    , podobienstwo  0.2536\n",
            "car        motorbike , podobienstwo  0.5413\n",
            "car        flower    , podobienstwo  0.3884\n",
            "motorbike  flower    , podobienstwo  0.2705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vk_wBDO8ADL8"
      },
      "execution_count": 82,
      "outputs": []
    }
  ]
}